{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Ocean Data Experimentation\n",
    "\n",
    "In this, we're going to learn how to manipulate the dataset to tell the stories we want to tell.\n",
    "\n",
    "There's a lot we can do with the dataset once we import it.\n",
    "\n",
    "Let's do that, along with all the other cool Python libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24259, 14)\n"
     ]
    }
   ],
   "source": [
    "# Import the stuff we need\n",
    "import pandas as pd # Pandas: Turn spreadsheets into useful DataFrame objects\n",
    "import numpy as np # NumPy: Handy math functions\n",
    "import seaborn as sns # Seaborn: Pretty graphs/charts\n",
    "import matplotlib.pyplot as plt # Matplotlib: What pandas and seaborn use under the hood\n",
    "\n",
    "# Create a dataframe from the raw CSV data file\n",
    "df = pd.read_csv(\"wod.csv\").drop(\"datetime.1\",axis=1).set_index(pd.DatetimeIndex(df.datetime))\n",
    "# Check out the shape of the DataFrame (rows/columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kind of a lot going on in there already. First we imported a whole bunch of Python modules that we use to work with our dataset. You'll see them in use as we go through the example code. For now, the most important module we need to know about is **pandas**. Pandas is an amazing tool for data science that lets us turn raw data into a special data type known as a **DataFrame**. Think of DataFrames as spreadsheets that you can store and manipulate with code.\n",
    "\n",
    "Working with spreadsheets is one way of analyzing data, but as your datasets get larger, this kind of \"manual\" analysis gets more and more unwieldy. \n",
    "\n",
    "Take a look up there at what `print(df.info())` says about our DataFrame. It has 24,259 rows and 14 columns. That's..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339626"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24259 * 14 # Don't judge me. I learned programming so I wouldn't have to do arithmetic in my head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...individual pieces of data. That's just too much to work with in a spreadsheet. Besides, this way, no errant clicks will damage our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with DataFrame\n",
    "\n",
    "DataFrames exist to make working with data easier. But like all objects in code, we have to know the **methods** that we can use. [This link](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) will take you to a full list of what DataFrames can do, but let's give a few useful examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic DataFrame Info\n",
    "It's always good to know how much data you're working with, and what kind. For that, we have the `shape` property and the `info()` method. `shape` shows us a pair of values, indicating how many rows/columns our DataFrame has. Let's try it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24259, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape) # Note that shape is a property, not a function that we call with ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`info()` will give us a rundown of each column in the DataFrame, as well as the DataFrame's **index**.\n",
    "\n",
    "### Index\n",
    "\n",
    "A DataFrame's index is like its built-in x-axis. When we go about graphing individual columns, you'll see that we never have to provide an x-axis value, because pandas uses the index by default. Let's look at the info for our DataFrame now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 24259 entries, 2010-01-23 11:00:00 to 2016-11-21 08:00:00\n",
      "Data columns (total 14 columns):\n",
      "datetime               24259 non-null object\n",
      "depth                  24259 non-null float64\n",
      "depth_qc               24259 non-null int64\n",
      "oxygen                 23413 non-null float64\n",
      "salinity               23447 non-null float64\n",
      "salinity_qc_flag       23447 non-null float64\n",
      "temperature            23875 non-null float64\n",
      "temperature_qc_flag    23875 non-null float64\n",
      "latitude               24259 non-null float64\n",
      "longitude              24259 non-null float64\n",
      "year                   24259 non-null int64\n",
      "month                  24259 non-null int64\n",
      "day                    24259 non-null int64\n",
      "time                   24259 non-null float64\n",
      "dtypes: float64(9), int64(4), object(1)\n",
      "memory usage: 3.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice right up top that this DataFrame has a `DatetimeIndex`. The other option would be a `RangeIndex`, which would just mean a row number. `DatetimeIndex` is handy, which we'll see shortly.\n",
    "\n",
    "You also see what columns are available for use. Looks like we have `depth`, `oxygen`, `salinity`, and `temperature` among others.\n",
    "\n",
    "Be aware that not all the columns have data in each row. If you don't see a `24259` next to the column name, there's some missing data. Keep that in mind when analyzing.\n",
    "\n",
    "Now that we know the shape of the data, Let's take a look at the values themselves. `head()` gives us a quick preview of the first few rows of our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                datetime  depth  depth_qc  oxygen  salinity  \\\n",
      "datetime                                                                      \n",
      "2010-01-23 11:00:00  2010-01-23 11:00:00    0.0         0    5.65    33.380   \n",
      "2010-01-23 11:00:00  2010-01-23 11:00:00    5.0         0    5.65    33.383   \n",
      "2010-01-23 11:00:00  2010-01-23 11:00:00   10.0         0    5.64    33.378   \n",
      "2010-01-23 11:00:00  2010-01-23 11:00:00   15.0         0    5.64    33.378   \n",
      "2010-01-23 11:00:00  2010-01-23 11:00:00   20.0         0    5.64    33.379   \n",
      "\n",
      "                     salinity_qc_flag  temperature  temperature_qc_flag  \\\n",
      "datetime                                                                  \n",
      "2010-01-23 11:00:00               0.0        14.32                  0.0   \n",
      "2010-01-23 11:00:00               0.0        14.33                  0.0   \n",
      "2010-01-23 11:00:00               0.0        14.34                  0.0   \n",
      "2010-01-23 11:00:00               0.0        14.33                  0.0   \n",
      "2010-01-23 11:00:00               0.0        14.34                  0.0   \n",
      "\n",
      "                     latitude  longitude  year  month  day   time  \n",
      "datetime                                                           \n",
      "2010-01-23 11:00:00    33.318   -119.668  2010      1   23  11.77  \n",
      "2010-01-23 11:00:00    33.318   -119.668  2010      1   23  11.77  \n",
      "2010-01-23 11:00:00    33.318   -119.668  2010      1   23  11.77  \n",
      "2010-01-23 11:00:00    33.318   -119.668  2010      1   23  11.77  \n",
      "2010-01-23 11:00:00    33.318   -119.668  2010      1   23  11.77  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. Let's drill down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing single columns\n",
    "\n",
    "If I want to look at _just_ temperature (and the index, of course), I can select that column with the syntax:\n",
    "\n",
    "```python\n",
    "df[\"temperature\"]\n",
    "```\n",
    "That provides a Series (like a 1-column DataFrame) with just temperature. Check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2010-01-23 11:00:00    14.32\n",
      "2010-01-23 11:00:00    14.33\n",
      "2010-01-23 11:00:00    14.34\n",
      "2010-01-23 11:00:00    14.33\n",
      "2010-01-23 11:00:00    14.34\n",
      "Name: temperature, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "temps = df[\"temperature\"] # Change this to another column to see what you get!\n",
    "print(temps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "\n",
    "Sometimes you don't want _all_ the data. Sometimes you just want a piece. Filtering helps us with that. Let's say I only want data from Januaries. As in, I want to know what things were like across our date range, but _only_ in January.\n",
    "\n",
    "Helpfully, our DataFrame has a `month` column in it, where numbers `1` to `12` indicate the month of the row's data. Just like we used a column name to get only a single column, we can use a **boolean expression** to filter our data down to just rows that match our expression.\n",
    "\n",
    "Remember that boolean expressions evaluate to `True` or `False`. So if I were to say \"Only January,\" in our DataFrame, the expression would be:\n",
    "\n",
    "```python\n",
    "df[\"month\"] == 1\n",
    "```\n",
    "\n",
    "When I put that whole thing in brackets, I get a filtered DataFrame with just the rows that match the expression. We'll also grab data from Mays for comparison. Try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 14)\n",
      "jans average month: 1.0\n",
      "mays average month: 5.0\n"
     ]
    }
   ],
   "source": [
    "jans = df[df[\"month\"] == 1]\n",
    "mays = df[df[\"month\"] == 5]\n",
    "print(mays.shape)\n",
    "# Get the average of the month # in January to prove it's only Januaries\n",
    "print(\"jans average month:\", jans[\"month\"].mean()) # Cool trick, right?\n",
    "print(\"mays average month:\", mays[\"month\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter data based on limits. Let's find out what the maximum, minimum, median, and average depth in our dataset is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth:  3500.0\n",
      "Min depth:  0.0\n",
      "Avg depth:  161.7344078486335\n",
      "Median depth:  80.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Max depth: \", df[\"depth\"].max())\n",
    "print(\"Min depth: \", df[\"depth\"].min())\n",
    "print(\"Avg depth: \", df[\"depth\"].mean())\n",
    "print(\"Median depth: \", df[\"depth\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sooo, it's pretty clear that most of our data is _not_ up at 3500. Later, we'll do a visual analysis for more clarity on this. But for now, let's keep our depth data to 200 feet and higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17321, 14)\n"
     ]
    }
   ],
   "source": [
    "filtered_depth = df[df[\"depth\"] <= 200] # Play with the number to see how the shape changes!\n",
    "print(filtered_depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
